{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection('blog', embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(client=chroma_client, collection_name='blog', embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_message = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(example_message[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programacion\\langchain\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'id': 36, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.', 'tokens': 'inquired about current trends in anticancer drug discovery selected target requested scaffold targeting these compounds once the compound was identified the model attempted its synthesis'}, page_content='inquired about current trends in anticancer drug discovery selected target requested scaffold targeting these compounds once the compound was identified the model attempted its synthesis'), -0.3198669264430378), (Document(metadata={'id': 46, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",', 'tokens': 'here are sample conversation for task clarification sent to openai chatcompletion endpoint used by gptengineer the user inputs are wrapped in user input text role system content you will read instructions and not carry them out only seek to clarify themnspecifically you will first summarise list of super short bullets of areas that need clarificationnthen you will pick one clarifying question and wait for an answer from the usern role user content we are writing super mario game in python mvc components split in separate files keyboard controln role assistant'}, page_content='here are sample conversation for task clarification sent to openai chatcompletion endpoint used by gptengineer the user inputs are wrapped in user input text role system content you will read instructions and not carry them out only seek to clarify themnspecifically you will first summarise list of super short bullets of areas that need clarificationnthen you will pick one clarifying question and wait for an answer from the usern role user content we are writing super mario game in python mvc components split in separate files keyboard controln role assistant'), -0.34635622121077403), (Document(metadata={'id': 11, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.', 'tokens': 'to avoid overfitting coh adds regularization term to maximize the loglikelihood of the pretraining dataset to avoid shortcutting and copying because there are many common words in feedback sequences they randomly mask of past tokens during training the training dataset in their experiments is combination of webgpt comparisons summarization from human feedback and human preference dataset'}, page_content='to avoid overfitting coh adds regularization term to maximize the loglikelihood of the pretraining dataset to avoid shortcutting and copying because there are many common words in feedback sequences they randomly mask of past tokens during training the training dataset in their experiments is combination of webgpt comparisons summarization from human feedback and human preference dataset'), -0.360317080348006), (Document(metadata={'id': 29, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\", 'tokens': 'task execution expert models execute on the specific tasks and log results instruction with the input and the inference results the ai assistant needs to describe the process and results the previous stages can be formed as user input user input task planning tasks model selection model assignment task execution predictions you must first answer the users request in straightforward manner then describe the task process and show your analysis and model inference results to the user in the first person if inference results contain file path must tell the user the complete file path'}, page_content='task execution expert models execute on the specific tasks and log results instruction with the input and the inference results the ai assistant needs to describe the process and results the previous stages can be formed as user input user input task planning tasks model selection model assignment task execution predictions you must first answer the users request in straightforward manner then describe the task process and show your analysis and model inference results to the user in the first person if inference results contain file path must tell the user the complete file path'), -0.36909241665714565)]\n",
      "  warnings.warn(\n",
      "d:\\Programacion\\langchain\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rater agreement is a statistical measure that assesses the consistency of judgments made by two or more raters. It quantifies the level of agreement between raters on a particular task, such as evaluating essays or classifying images.  Rater agreement is important for ensuring the reliability and validity of research findings. \n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "for chunk in rag_chain.stream(\"What is Rater Agreement?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear una Chain personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    'Usted es un asistente para tareas de respuesta a preguntas. '\n",
    "    'Si el texto de entrada esta en un idioma diferente al español, traduzca el texto al español.'\n",
    "    'Utilice las siguientes piezas de contexto recuperado para responder '\n",
    "    'la pregunta. Si no sabes la respuesta, di que '\n",
    "    'No lo sé. Utilice tres oraciones como máximo y mantenga el '\n",
    "    'respuesta concisa.'\n",
    "    '\\n\\n'\n",
    "    '{context}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programacion\\langchain\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'id': 19, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.', 'tokens': 'lsh localitysensitive hashing it introduces hashing function such that similar input items are mapped to the same buckets with high probability where the number of buckets is much smaller than the number of inputs annoy approximate nearest neighbors oh yeah the core data structure are random projection trees set of binary trees where each nonleaf node represents hyperplane splitting the input space into half and each leaf stores one data point trees are built independently and at random so to some extent it mimics hashing function annoy search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results the idea is quite related to kd tree but lot more scalable'}, page_content='lsh localitysensitive hashing it introduces hashing function such that similar input items are mapped to the same buckets with high probability where the number of buckets is much smaller than the number of inputs annoy approximate nearest neighbors oh yeah the core data structure are random projection trees set of binary trees where each nonleaf node represents hyperplane splitting the input space into half and each leaf stores one data point trees are built independently and at random so to some extent it mimics hashing function annoy search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results the idea is quite related to kd tree but lot more scalable'), -0.3699190531249714), (Document(metadata={'id': 36, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.', 'tokens': 'inquired about current trends in anticancer drug discovery selected target requested scaffold targeting these compounds once the compound was identified the model attempted its synthesis'}, page_content='inquired about current trends in anticancer drug discovery selected target requested scaffold targeting these compounds once the compound was identified the model attempted its synthesis'), -0.37119397384772634), (Document(metadata={'id': 29, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\", 'tokens': 'task execution expert models execute on the specific tasks and log results instruction with the input and the inference results the ai assistant needs to describe the process and results the previous stages can be formed as user input user input task planning tasks model selection model assignment task execution predictions you must first answer the users request in straightforward manner then describe the task process and show your analysis and model inference results to the user in the first person if inference results contain file path must tell the user the complete file path'}, page_content='task execution expert models execute on the specific tasks and log results instruction with the input and the inference results the ai assistant needs to describe the process and results the previous stages can be formed as user input user input task planning tasks model selection model assignment task execution predictions you must first answer the users request in straightforward manner then describe the task process and show your analysis and model inference results to the user in the first person if inference results contain file path must tell the user the complete file path'), -0.3757832764431921), (Document(metadata={'id': 53, 'metadata': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'page_content': 'pytest\\ndataclasses', 'tokens': 'pytest dataclasses'}, page_content='pytest dataclasses'), -0.38460404683212457)]\n",
      "  warnings.warn(\n",
      "d:\\Programacion\\langchain\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La descomposición de tareas es el proceso de dividir una tarea grande y compleja en tareas más pequeñas y manejables. Esto ayuda a simplificar el trabajo, hacerlo más fácil de entender y administrar, y facilita la asignación de responsabilidades a diferentes personas o equipos. La descomposición de tareas es una técnica común utilizada en la gestión de proyectos, la ingeniería y otras áreas donde se necesitan tareas complejas. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain_2 = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain_2.invoke({\"input\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
