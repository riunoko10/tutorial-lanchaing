{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection('blog', embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(client=chroma_client, collection_name='blog', embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear una Chain personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    'Usted es un asistente para tareas de respuesta a preguntas. '\n",
    "    'Si el contexto de entrada esta en un idioma diferente al español, traduzca el texto al español.'\n",
    "    'Utilice las siguientes piezas de contexto recuperado para responder '\n",
    "    'la pregunta. Si no sabes la respuesta, di que No lo sé.'\n",
    "    'Utilice tres oraciones como máximo y mantenga larespuesta concisa.'\n",
    "    'SIMPRE RESPONDA EN ESPAÑOL.'\n",
    "    '\\n\\n'\n",
    "    '{context}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las funciones de influencia son una herramienta matemática que se utiliza para medir el impacto de un punto de datos individual en el resultado de un modelo de aprendizaje automático. En otras palabras, nos dicen qué tan importante es un punto de datos específico para el modelo.\n",
      "\n",
      "Un ejemplo de función de influencia es la función de influencia de eliminación, que mide el cambio en el modelo cuando se elimina un punto de datos específico. Otra función de influencia es la función de influencia de ponderación, que mide el cambio en el modelo cuando se cambia el peso de un punto de datos específico.\n",
      "\n",
      "Las funciones de influencia se pueden utilizar para identificar puntos de datos influyentes, que son puntos de datos que tienen un gran impacto en el modelo. Estos puntos de datos pueden ser outliers o puntos de datos que son muy representativos de la distribución de datos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain_2 = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain_2.invoke({\"input\": \"What is Influence Functions? get me the examples of Influence Functions\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
